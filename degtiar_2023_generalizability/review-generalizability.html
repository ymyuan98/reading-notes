<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.549">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ming Yuan">

<title>Reading note: A Review of Generalizability and Transportability</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="review-generalizability_files/libs/clipboard/clipboard.min.js"></script>
<script src="review-generalizability_files/libs/quarto-html/quarto.js"></script>
<script src="review-generalizability_files/libs/quarto-html/popper.min.js"></script>
<script src="review-generalizability_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="review-generalizability_files/libs/quarto-html/anchor.min.js"></script>
<link href="review-generalizability_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="review-generalizability_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="review-generalizability_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="review-generalizability_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="review-generalizability_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Reading note: A Review of Generalizability and Transportability</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Ming Yuan </p>
          </div>
  </div>
    
  
    
  </div>
  


</header>


<blockquote class="blockquote">
<p>Degtiar I, Rose S. A Review of Generalizability and Transportability. Annual Review of Statistics and Its Application. 2023;10(1):501–24. <a href="https://doi.org/10.1146/annurev-statistics-042522103837" class="uri">https://doi.org/10.1146/annurev-statistics-042522103837</a></p>
</blockquote>
<section id="keywords-of-the-paper" class="level2">
<h2 class="anchored" data-anchor-id="keywords-of-the-paper">Keywords of the paper</h2>
<p>generalizability, transportability, external validatiy, treatment effect heterogeneity, causal inference</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">1. Introduction</h2>
<ul>
<li><p>Target population: the particular population that we hope to gain understanding of.</p></li>
<li><p>Study population: a hypothetical population that the study sample represents, defined by enrollment processes and inclusion or exclusion criteria.</p></li>
<li><p>Target and study population are usually different.</p></li>
<li><p>Analysis population: created by post-enrollment, further dropout and missingness.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="st100501.f1.jpeg" class="img-fluid figure-img"></p>
<figcaption>Figure 1: Internal vs external validity biases as they relate to target, study, and analysis populations.</figcaption>
</figure>
</div>
<p><strong>Key concepts of extending causal inferences beyond a study sample</strong>:</p>
<ol type="1">
<li><p>Generalizability: the study population is a subset of the target population of interest.</p></li>
<li><p>Transportability: the study population is (at least partly) external to the target population.</p></li>
<li><p>Internal validity: defined as an effect estimation being unbiased for the causal treatment effect in the population from which the sample is a simple random sample.</p></li>
<li><p>External validity: how well results generalize or transport to other contexts, specifically that the (internally valid) effect estimate is unbiased for the causal treatment effect in a different setting, such as a target population of interest. (<em>External validity bias = sample selection bias</em>)</p></li>
<li><p>Confounder: factors associated with both the treatment and the outcome, which causes spurious treatment-outcome associations.</p></li>
<li><p>Effect modifier: factor whose levels associated with different treatment effects.</p></li>
</ol>
<p><strong>External validity bias</strong> arises from differences between the study and target populations in (a) subject characteristics; (b) settings, such as geography or type of health center; (c) treatment, such as timing, dosage, or staff training; (d) outcomes, such as length of follow-up or timing of measurements. (cited..).</p>
<p>Most generalizability and transportability methods address differences in subject characteristics (a) and assume all the other threats do not exist in the data sources they are looking to generalize across.</p>
<p>Then, external validity bias arises solely from (a1) variation in the probability of enrollment in the study, (b1) heterogeneity in treatments, and (c1) the correlation between items (a1) and (b1). (cited..).</p>
<p>Therefore, we distinguish between factors differentiating the target population from the study population (external validity bias) and those that create differences between treatment groups (internal validity bias), e.g.&nbsp;confounders.</p>
<p>The optimal solution to external validity bias centers on <strong>study design</strong>.</p>
<ul>
<li><p>One ideal design would randomly sample subjects from the target population and then randomly assign treatment to the selected individuals. (INFEASIBLE!).</p></li>
<li><p>Alternative study designs includes <em>purposive sampling</em>, in which investigators deliberately select individuals for reasons such as representative or heterogeneity; <em>pragmatic or practical clinical trials</em>, which aim to be representative of clinical practice; <em>stratified selection</em> based on effect modifiers or propensity scores for selection; and <em>balanced sampling designs</em> for site selection that select representative sites through stratified ranked sampling. (cited..).</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="st100501.f2.jpeg" class="img-fluid figure-img"></p>
<figcaption>Figure 2: Framework of assessing and addressing external validity bias after data collection.</figcaption>
</figure>
</div>
</section>
<section id="estimand" class="level2">
<h2 class="anchored" data-anchor-id="estimand">2. Estimand</h2>
<section id="notations" class="level3">
<h3 class="anchored" data-anchor-id="notations">2.1 Notations:</h3>
<ul>
<li><p><span class="math inline">\(Y\)</span>: outcome;</p></li>
<li><p><span class="math inline">\(A \in \{0,1\}\)</span>: (binary) treatment;</p></li>
<li><p><span class="math inline">\(\mathbf{X} \in \mathbb{R}^d\)</span>: baseline covariates, including all potential treatment effect confounders and effect modifiers that differ between the study and target populations;</p></li>
<li><p><span class="math inline">\(S=1\)</span>: an indicator of subject being included in the study sample;</p></li>
<li><p><span class="math inline">\(O_{\text{study}} = (\mathbf{X}, A,Y, S=1)\)</span>: an observational unit for the <strong>study sample</strong>;</p></li>
<li><p><span class="math inline">\(P_{\text{study}} \in \mathcal{M}_{\text{study}}\)</span>: probability distribution of <span class="math inline">\(O_{\text{study}}\)</span>, where <span class="math inline">\(\mathcal{M}_{\text{study}}\)</span> is the collection of possible probability distributions (i.e., statistical model);</p></li>
<li><p><span class="math inline">\(n_{s}\)</span>: sample size of <span class="math inline">\(O_{\text{study}}\)</span>, indexed by <span class="math inline">\(j\)</span>.</p></li>
<li><p><span class="math inline">\(O = (\mathbf{X}, A, Y, S) \sim P \in \mathcal{M}\)</span>: an observational unit for a representative sample from the <strong>target population</strong>;</p></li>
<li><p><span class="math inline">\(n\)</span>: sample size of <span class="math inline">\(O\)</span>, indexed by <span class="math inline">\(i\)</span>.</p></li>
<li><p>Target sample subjects who do not appear in the study sample will have <span class="math inline">\(S=0\)</span>.</p></li>
</ul>
<p>Terminology “selected” or “sampled” are used throughout the article for simplicity, although for transportability, subjects are not directly sampled into the target population.</p>
<p>For generalizability, <span class="math inline">\(O_{\text{study}} \in O\)</span>; for transportability, <span class="math inline">\(O_{\text{study}} \notin O\)</span> (the two sets are disjoint).</p>
</section>
<section id="estimand-of-interest" class="level3">
<h3 class="anchored" data-anchor-id="estimand-of-interest">2.2 Estimand of interest:</h3>
<p>The <code>target population average treatment effect (PATE)</code>:<br>
<span class="math display">\[
\tau = \mathbb{E}(Y^{(1)} - Y^{(0)}) =
\mathbb{E}_{\mathbf{X}}[E(Y|S=1, A=1, \mathbf{X})] - \mathbb{E}_{\mathbf{X}}[E(Y|S=1, A=0, \mathbf{X})]
\]</span><br>
Its corresponding estimator:<br>
<span class="math display">\[
\hat{\tau} = \frac{1}{n} \sum_{i=1}^n \left(\hat{Y}_i^{(1)} - \hat{Y}_i^{(0)} \right).
\]</span><br>
<br>
Different target populations correspond to alternative PATEs because the expectation is taken with respect to alternative distributions of covariates <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p>However, since we only observe outcomes in the study sample, the study directly estimates the <code>sample average treatment effect (SATE)</code>: <span class="math display">\[
\tau_s = \mathbb{E}(Y^{(1)} - Y^{(0)}|S = 1)
\]</span> with estimator <span class="math display">\[
\hat{\tau}_s = \frac{1}{n_s} \sum_{j=1}^{n_s} \left(\hat{Y}_j^{(1)} - \hat{Y}_j^{(0)} \right).
\]</span></p>
<p>Other estimands of interest:<br>
E.g. the <code>target population conditional average treatment effects (PCATEs)</code>: <span class="math display">\[
\tau_x = \mathbb{E}(Y^{(1)} - Y^{(0)}|\mathbf{X});
\]</span> the <code>target population average treatment effects among the treated</code>: <span class="math display">\[
\tau_1 = \mathbb{E}(Y^{(1)} - Y^{(0)}|A=1),
\]</span> etc.</p>
</section>
<section id="relations-between-sate-pate-and-the-true-quantities" class="level3">
<h3 class="anchored" data-anchor-id="relations-between-sate-pate-and-the-true-quantities">2.3 Relations between SATE, PATE, and the true quantities:</h3>
<blockquote class="blockquote">
<ol type="1">
<li>When there is difference in the distributions of treatment effect modifiers between the study and target populations, which may induce external validity bias,<br>
SATE <span class="math inline">\(\neq\)</span> PATE in general.</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="2" type="1">
<li>Sampling variability and internal validity biases can also drive estimates of SATE further from the truth.</li>
</ol>
</blockquote>
<blockquote class="blockquote">
<ol start="3" type="1">
<li>Biases may differ in magnitude and may make the SATE either larger or smaller than the PATE.</li>
</ol>
</blockquote>
</section>
</section>
<section id="assumptions" class="level2">
<h2 class="anchored" data-anchor-id="assumptions">3. Assumptions</h2>
<section id="internal-validity" class="level3">
<h3 class="anchored" data-anchor-id="internal-validity">3.1 Internal validity</h3>
<p><code>Assumption 1 (Conditional treatment exchangeability)</code>: <span class="math inline">\(Y^{(a)} \perp\!\!\perp A | \mathbf{X}, S = 1\)</span> for all <span class="math inline">\(a \in \mathcal{A}\)</span>, the set of all possible treatments.</p>
<ul>
<li>No unmeasured confounding factors.</li>
</ul>
<p>This condition is sufficient, but not necessary. When estimating the PATE, it can be replaced by (the weaker condition of) the mean conditional exchangeability of the treatment effect: <span class="math inline">\(\mathbb{E}(Y^{(1)} - Y^{(0)}|\mathbf{X}, A, S=1) = \mathbb{E}(Y^{(1)} - Y^{(0)}|\mathbf{X}, S=1)\)</span>.</p>
<p><code>Assumption 2 (Positivity of treatment assignment)</code>: <span class="math inline">\(P(\mathbf{X}=\mathbf{x}|S=1)&gt;0 \Rightarrow P(A = a|\mathbf{X}=\mathbf{x}, S=1)&gt;0\)</span>, with probability 1 for all <span class="math inline">\(a \in \mathcal{A}\)</span>.</p>
<ul>
<li>Each sugject in the study has a positive probability of receiving each version of the treatment.<br>
</li>
<li>In the combination of the conditional treatment exchangeability assumption above, this assumption is known as strong ignorable treatment assignment.</li>
</ul>
<p><code>Assumption 3 (Stable unit treatment value assumption (SUTVA) for treatment assignment)</code>: If <span class="math inline">\(A = a\)</span>, then <span class="math inline">\(Y = Y^{(a)}\)</span>.</p>
<ul>
<li>It requires no interference between subjects and treatment version irrelevance in the study and target populations.</li>
</ul>
</section>
<section id="external-validity" class="level3">
<h3 class="anchored" data-anchor-id="external-validity">3.2 External Validity</h3>
<p><code>Assumption 4 (Conditional exchangeability for study selection)</code>: <span class="math inline">\(Y^{(a)} \perp\!\!\perp S | \mathbf{X}\)</span> for all <span class="math inline">\(a \in \mathcal{A}\)</span>.</p>
<ul>
<li><p>Also known as exchangeability over selection and the generalizability assumption.</p></li>
<li><p>It requires the outcomes <span class="math inline">\(Y^{(a)}\)</span>among individuals with the same treatment <span class="math inline">\(A = a\)</span> and covariate values <span class="math inline">\(\mathbf{X} = \mathbf{x}\)</span> in the study and target populations are the same.</p></li>
<li><p>All effect modifiers that differ between study and target populations must be measured.</p></li>
<li><p>When calculating PATEs, this assumptions can be replaced by a weaker condition, the mean conditional exchangeability of selection: <span class="math inline">\(\mathbb{E}(Y^{(1)} - Y^{(0)}|\mathbf{X}, S=1) = \mathbb{E}(Y^{(1)} - Y^{(0)}|\mathbf{X})\)</span>.</p></li>
</ul>
<p><code>Assumption 5 (Positivity of selection)</code>: <span class="math inline">\(P(\mathbf{X} = \mathbf{x}) &gt; 0 \Rightarrow P(S=1|\mathbf{X} = \mathbf{x}) &gt; 0\)</span> with probability 1.</p>
<ul>
<li><p>Requires common support with respect to study selection;</p></li>
<li><p>In every stratum of effect modifiers, there is a positive probability of being in the study sample or being represented by study participants.</p></li>
<li><p>It can be replaced by smoothing assumptions under a parametric model, for example, that the <em>propensity score distribution for study selection</em> has sufficient overlap or common support between the study sample and target population.</p></li>
<li><p>With conditional positivity of selection, we assume that all members of the target population are represented by individuals in the study.</p></li>
</ul>
<p><code>Assumption 6 (Stable unit treatment value assumption for study selection)</code>: If <span class="math inline">\(S = s\)</span> (and <span class="math inline">\(A = a\)</span>), then <span class="math inline">\(Y = Y^{(a)}\)</span>.</p>
<ul>
<li><p>No inference between subjects selected into the study vs those not selected and treatment version irrelevance between study and target samples (the same treatment is given to both).</p></li>
<li><p>It necessitates that there is no difference across study and target samples in how outcomes are measured or in how the intervention is applied, that there is a common data-generating function for the outcome across individuals in the study and target populations (i.e.&nbsp;that being in the study does not change treatment effects), and that the potential outcomes are not a function of the proportion of individuals selected for the study.</p></li>
</ul>
</section>
<section id="transportability" class="level3">
<h3 class="anchored" data-anchor-id="transportability">3.3 Transportability</h3>
<p>For <em>generalizability</em>, the study sample is a subset of the target population; therefore, the positivity assumption for selection will need to be bounded away from 0;</p>
<p>For <em>transportability</em>, the study sample is not a subset of the target population; thus, the <em>propensity to be in the study population</em> will need to be bounded away from 0 and 1. Besides, the set of covariates, <span class="math inline">\(\mathbf{X}\)</span>, required for conditional exchangeability for study selection cannot include those that separate the study sample from the target population.</p>
</section>
</section>
<section id="evaluating-generalizability-and-transportability" class="level2">
<h2 class="anchored" data-anchor-id="evaluating-generalizability-and-transportability">4. Evaluating Generalizability and Transportability</h2>
<p>External validity bias exists when study populations differ in their distribution of effect modifiers; these assessments therefore examine population differences and whether treatment effect heterogeneity exists.</p>
<section id="assessing-dissimilarity-between-populations-with-baseline-characteristics" class="level3">
<h3 class="anchored" data-anchor-id="assessing-dissimilarity-between-populations-with-baseline-characteristics">4.1 Assessing Dissimilarity Between Populations with Baseline Characteristics</h3>
<p>When only <em>summary-level study data</em> are available, it is possible to examine differences in <em>univariate covariate metrics</em> between study and target samples.</p>
<p><a href="https://pubmed.ncbi.nlm.nih.gov/28118923/">Cahan et al.&nbsp;(2017)</a>: propose a generalization score for evaluating clinical trials that incorporates <em>baseline patient characteristics, the trial setting, protocol, and patient selection</em>: it takes ratios of the mean of median values of these characteristics in the study and target samples and then averages across categories for an overall score. However, it does not account for any measures of dispersion, which may reflect the exclusion of more heterogeneous individuals from the study. When only baseline patient characteristics are responsible for relevent population differences, <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.3218">Greenhouse et al.&nbsp;(2008)</a> perform multiplicity-adjusted univariate tests for differences in modifiers between study and target samples, and <a href="https://pubmed.ncbi.nlm.nih.gov/27474752/">Tipton &amp; Peck (2017)</a> perform exaimination of absolute standardized mean differences(SMDs) for each covariate: <span class="math inline">\((\bar{X}_{\text{study}} - \bar{X}) / \sigma_{\bar{X}}\)</span>, where quantities without subscript “study” indicates the corresponding summary statistics of the target samples. High values indicate heavy extrapolation and reliance on correct model specification.</p>
<p>Examining the <em>joint (rather than the univariate) distributions of patient characteristics</em> more comprehensively assesses overlap. <a href="https://journals.sagepub.com/doi/abs/10.3102/1076998614558486">Tipton (2014)</a>: generalizability index that bins propensity scores and is bounded between 0 and 1. Besides, other propensity score distance measures can be used, such as Q-Q plots, etc., which largely focus on comparing cumulative densities. To assess the degree of extrapolation, one can examine overlap in the propensity of selection distributions, such as in <a href="https://pubmed.ncbi.nlm.nih.gov/27474752/">Tipton &amp; Peck (2017)</a> the proportion of target sample individuals with propensity scores outside the 5th and 95th percentiles of the sample propensity scores.</p>
<p>The machine learning literature <a href="https://ieeexplore.ieee.org/document/8071420">Glauner et al.&nbsp;(2017)</a> provides an alternative approach by detecting distributional shift of covariate between the study (training) and target (test) samples. First, they create a joint data set with target and study sample data, and then use a classification algorithm to predict whether the data come from the study. The dissimilarity between training and test data sets is suggested by a threshold of acceptability. However, this method does not rule out differences in effect modifiers. A low score might furthermore indicate an incorrect model specification or insufficient model tuning.</p>
<p>These tests require knowledge of which characteristics moderate the treatment effect (or are correlated with unmeasured effect modifiers) and what level of differences are substantively relevant. In a propensity score based approach that includes or tests more than one covariate, it prioritizes predictors that are strongly (statistically) associates with study selection rather than those that exhibit strong effect modification. Investigators should aim to <strong>identify relevant effect modifiers</strong> for testing or inclusion in the propensity score regression and test this subset.</p>
</section>
<section id="assessing-dissimilarity-between-populations-with-outcomes" class="level3">
<h3 class="anchored" data-anchor-id="assessing-dissimilarity-between-populations-with-outcomes">4.2 Assessing Dissimilarity Between Populations with Outcomes</h3>
<p>When individual-level outcome data or joint distributions of group-level outcome data are available in both the study and target samples for at least one of the treatment groups, the following methods can assess the extent to which <strong>measured effect modifiers</strong> account for population differences: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4051511/">Stuart et al.(2011)</a> compares the observed outcomes in the target sample with predicted outcomes using study controls. <a href="https://scholar.harvard.edu/imbens/files/predicting_the_efficacy_of_future_training_programs_using_past_experiences.pdf">Hotz et al.&nbsp;(2005)</a> compares study individuals who received the same treatment: <span class="math inline">\(1/n_a \sum_{i=1}^N 1(A_i = a) Y_i\)</span> vs <span class="math inline">\(1/n_{s,a} \sum_{i:S_i = 1}1(A_i = a)w_iY_i\)</span>, with weights <span class="math inline">\(w_i\)</span> defined by weighting and matching methods. <a href="https://academic.oup.com/jrsssa/article/178/3/757/7058621">Hartman et al.&nbsp;(2015)</a> formalizes this comparison with equivalence tests.</p>
<p>To detect <strong>unmeasured effect modification</strong>, we can compare these two quantities: <span class="math inline">\(\hat{\mathbb{E}}(Y|\mathbf{X}, A = a, S = 1)\)</span> (for study samples) vs <span class="math inline">\(\hat{\mathbb{E}}(Y|\mathbf{X}, A = a, S = 0)\)</span> (for nonstudy target samples), where <span class="math inline">\(\mathbf{X}\)</span> are the measured effect modifiers. Possible tests include analysis of covariance, Mantel-Haenszel, U-statistic-based tests, stratified log-rank, or stratified rank-sum, depending on the outcome. <a href="https://pubmed.ncbi.nlm.nih.gov/9253394/">Marcus (1997)</a> <a href="https://scholar.harvard.edu/imbens/files/predicting_the_efficacy_of_future_training_programs_using_past_experiences.pdf">Hotz et al.&nbsp;(2005)</a> <a href="https://academic.oup.com/jrsssb/article/81/1/75/7048373">Luedtke et al.&nbsp;(2019)</a></p>
<p>To assess the <strong>sufficiency of the estimation approach</strong>, <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3367517/">Pan &amp; Schaubel (2009)</a> tests for differences between study and target regression coefficients or between baseline hazards in a Cox regression. Any identified differences in outcomes or effects will reflect sample differences unaccounted for by the outcome or weighting method, indicating unmeasured effect modification or an ineffective modeling approach. To have this comparison reflect relevant differences, study controls must be representative of the target population after weighting or regression adjustment. <a href="https://academic.oup.com/jrsssa/article/178/3/757/7058621">Hartman et al.&nbsp;(2015)</a> provides a more formal set of identifiability assumptions that may be violated when each equivalence test is rejected. <strong>Sensitivity analysis</strong> can be performed to assess the extend to which it can impact results <a href="https://pubmed.ncbi.nlm.nih.gov/9253394/">Marcus (1997)</a> <a href="https://projecteuclid.org/journals/annals-of-applied-statistics/volume-11/issue-1/Sensitivity-analysis-for-an-unobserved-moderator-in-RCT-to-target/10.1214/16-AOAS1001.full">Nguyen et al.&nbsp;(2017)</a> <a href="https://pubmed.ncbi.nlm.nih.gov/36847107/">Dahabreh et al.&nbsp;(2019c)</a> or to generate bounds on the treatment effect when only partial identification is possible <a href="https://pubmed.ncbi.nlm.nih.gov/28211943/">Chan (2017)</a>.</p>
</section>
<section id="identifying-treatment-effect-heterogeneity" class="level3">
<h3 class="anchored" data-anchor-id="identifying-treatment-effect-heterogeneity">4.3 Identifying Treatment Effect Heterogeneity</h3>
<p>Tests of prespecified subgroups should focus on target population subgroups under- or over-represented in the study, or any other substantively relevant subgroup expected to exhibit effect heterogeneity.</p>
<p>When effect modifiers are known a priori, Methods that <em>test several effect modifiers individually</em> are <em>underpowered</em> to detect significant effects after incorporating <em>multiple testing adjustments</em>. To address this lack of power, sequential tests for identifying treatment-covariate interactions can be used <a href="">Qian et al.&nbsp;2019</a>. Alternative approaches include testing whether the conditional average treatment effect is identical across predefined subgroups <a href="">Crump et al.&nbsp;(2008)</a> <a href="">Green &amp; Kern (2012)</a>, comparing subgroup effects to average effects <a href="">Simon (1982)</a>, and identifying qualitative interactions or treatment differences exceeding a prespecified relevant threshold <a href="">Gail &amp; Simon (1985)</a>.</p>
<p>When effect modifiers are not known a priori, a variety of techniques identify subgroups with heterogeneous effects. These include those that identify variables that qualitatively interact with treatment (i.e., for which the optimal treatment differs by subgroups) <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3003934/">Guter et al.&nbsp;(2011)</a>, and determine the magnitude of interaction <a href="">Tian et al.&nbsp;(2014)</a> <a href="">Chen et al.&nbsp;(2017)</a>. <em>Machine learning approaches</em> also identify subgroups with heterogeneous treatment effects while minimizing modeling assumptions. Approaches that also present tests for treatment effect differences between subgroups include Bayesian additive regression trees (BARTs) and other classification and regression tree (CART) variants (tree-based methods!) <a href="">Su et al.&nbsp;(2008)</a> <a href="">Su et al.&nbsp;(2009)</a> <a href="">Green &amp; Kern (2012)</a> <a href="">Athey &amp; Imbens (2016)</a> Tree-based methods develop partitions in the covariate space recursively to grow toward terminal nodes with homogeneity for the outcome. May be particularly useful when heterogeneity may be a function of a more complex combination of factors.</p>
<p>At the existence of many effect modifiers, or when effect modifiers are unknown, <strong>global tests</strong> for heterogeneity can be used, which is to identify whether treatment effect heterogeneity exists. However, these tests do not identify effect modifiers; if a global test is rejected, one can then compare individual subgroups to determine which demonstrate effect heterogeneity. (Methods…)</p>
<p>If these assessments of generalizability fail and the target population is not well-represented by the study population (specifically, when strong ignorability fails), <a href="">Tipton (2013b)</a> provides recommended paths forward. Investigators can change the target population to one represented by the study. Alternatively, investigators can retain the original target population and note the limitations of extrapolated results and likelihood of remnant bias.</p>
</section>
</section>
<section id="methods-for-estimating-population-average-treatment-effects." class="level2">
<h2 class="anchored" data-anchor-id="methods-for-estimating-population-average-treatment-effects.">5. Methods for Estimating Population Average Treatment Effects.</h2>
<p>The following analytic methods are developed to generalize or transport results from randomized or observational data to a target population.</p>
<p>To mitigate external validity bias, generalizability and transportability methods address differences in the distribution of effect modifiers between study and target populations.</p>
<section id="matching-and-weighting-methods" class="level3">
<h3 class="anchored" data-anchor-id="matching-and-weighting-methods">5.1 Matching and Weighting Methods</h3>
<p>Matching and weighting-based approaches account for the probability of selection into the study rather than the probability of treatment assignment.</p>
<p>These methods are effective when effect modifiers strongly predict selection into the study. They strongly rely on common covariate support between study and target populations and perform poorly when a portion of the target population is not well-represented in the study sample or when empirical positivity violations occur.</p>
<p>Including unecessary covariates can decrease precision, increase the chance of extreme weights and difficult-to-match subjects, and provide no bias reduction. <a href="">Nie et al.&nbsp;(2013)</a> Failing to include an effect modifier is more of a concern than including unnecessary covariates <a href="">Stuart (2010)</a> <a href="">Dahabreh et al.&nbsp;(2020)</a>.</p>
<section id="matching" class="level4">
<h4 class="anchored" data-anchor-id="matching">5.1.1 Matching</h4>
<p><strong>Full matching</strong>:<a href="">Staurt et al.&nbsp;(2011)</a></p>
<ul>
<li><p>This approach fully matches study and target sample individuals based on <em>propensity scores</em> to form sets, each with at least one study and target individual.</p></li>
<li><p><em>Individual’s outcomes</em> are then <strong>reweighted</strong> by the number of target individuals in their matched set.</p></li>
<li><p>This approach <em>relies heavily on the distance metric</em>, which can be misled by covariates that do not affect the outcome.</p></li>
</ul>
<p><strong>Fine balance</strong>: <a href="">Bennet et al.&nbsp;(2020)</a></p>
<ul>
<li><p>This approach matches samples to a target population to achieve fine balance on <em>covariate means</em> rather than working with the propensity score.</p></li>
<li><p>For example, each clinic patient would be matched to a treated and a control patient in the RCT to attain balance on the marginal distributions of <span class="math inline">\(\mathbf{X}\)</span>s.</p></li>
<li><p>It is a computationally efficient approach that accommodates multivalued treatments.</p></li>
</ul>
<p>Matching methods require calibration for <strong>bias-variance trade-off</strong> such as via a caliper or by choosing the ratio of study to target individuals to match.</p>
</section>
<section id="weighting" class="level4">
<h4 class="anchored" data-anchor-id="weighting">5.1.2 Weighting</h4>
<p>In low-dimensional setting with categorical or binary covariates, nonparametric <strong>poststratification</strong> (also known as direct adjustment or subclassification) has been used with randomized data and with observational data in the context of instrumental variables. Poststratification obtains estimates for each stratum of effect modifiers, then reweights these estimates to the effect modifier distribution in the target population:<span class="math display">\[
\hat{\mathbb{E}}[Y^{(a)}] = \frac{1}{n} \sum_{l=1}^L n_l \bar{Y}_{l}^{(a)},
\]</span><br>
where <span class="math inline">\(L\)</span> is the number of strata, <span class="math inline">\(n_l\)</span> is the target sample size in stratum <span class="math inline">\(l\)</span>, <span class="math inline">\(n = \sum_{l=1}^L n_l\)</span>, and <span class="math inline">\(\bar{Y}_l^{(a)}\)</span> is an estimate from study sample data of the potential outcome on treatment <span class="math inline">\(a\)</span> in stratum <span class="math inline">\(l\)</span>, commonly the stratum-specific sample mean for subjects on treatment <span class="math inline">\(a\)</span>.</p>
<p>When there are <strong>insufficient strata</strong> (e.g.&nbsp;empty strata), which is usually an issue with continuous variables or many stratifying variables, <strong>residual external validity bias remains</strong>. To address it, inference can be <strong>pooled across strata</strong> using mltilevel regression with poststratification. For higher-dimensional settings or with continuous covariates, flexible nonparametric approaches can be applied, such as maximum entropy weighting <a href="">Hartman et al.&nbsp;(2015)</a>.</p>
<p>Most weighting approaches uses a propensity of study selection regression to construct weights. They rely on <strong>correct specification of the propensity score regression</strong> and <strong>sufficient propensity score overlap between study subjects and target sample individuals not in the study.</strong> The most straightforward weighting approaches tend to have large variances in the presence of extreme weights: give disproportionate weight to outlier observations, and produce outcome estimates outside the support of the outcome variable. <strong>Weight standardization</strong> as well as <strong>weight trimming</strong> can address these issues, although the latter one requires a bias-variance trade-off as it induces bias by changing the target population of interest.</p>
<p>For <strong>generalizability</strong>:</p>
<p><strong>Inverse probability of participation weighting (IPPW)</strong> (cited…). It weights the outcome for each study individual on treatment <span class="math inline">\(a\)</span> by the inverse probability (propensity) of being in the study. Weights have been developed for estimating PATEs, including those that incorporate treatment assignment to account for covariate imbalances in an RCT or for confounding in an observational study.</p>
<p>The observed outcomes are reweighted to obtain the potential outcomes for each treatment group <span class="math inline">\(a\)</span> <a href="">Stuart et al.&nbsp;(2011)</a> <a href="">Dahabreh et al.&nbsp;(2019b)</a>: <span class="math display">\[
\mathbb{E}(Y^{(a)}) = \frac{1}{n} \sum_{i=1}^n w_i Y_i, \\
w_i = \frac{1}{\pi_{s, i} \pi_{a, i}} I(S_i = 1) I (A_i = a),
\]</span><br>
where <span class="math inline">\(\pi_{s, i} = P(S_i = 1|X_i)\)</span> is the propensity score for selection into the study, and <span class="math inline">\(\pi_{a,i} = P(A_i = a|S_i = 1, X_i)\)</span> is the propensity score for assignment to treatment <span class="math inline">\(a\)</span> in the study. The latter can be ignored under random treatment assignment cases <a href="">Lesko et al.&nbsp;(2017)</a>.</p>
<p>Individual-level data are required for calculating IPPW weights. However, power can become an issue, particularly for multilevel treatments.</p>
<p>These methods also perform poorly when study selection probability is small. IPPW has also been developed for regression parameters in a generalized linear model <a href="">Haneuse et al.&nbsp;(2009)</a>.</p>
<p>For <strong>transportability</strong> to the target population <span class="math inline">\(S=0\)</span>:</p>
<p><strong>odds of participation weights</strong> are used <a href="">Westreich et al.&nbsp;(2017)</a> <a href="">Dahabreh et al.&nbsp;(2020)</a>. The estimator of expected potential outcome of the target population is given by <a href="">Dahabreh et al.&nbsp;(2020)</a> <span class="math display">\[
\mathbb{E}(Y^{(a)}|S=0) = \frac{1}{n} \sum_{i=1}^N w_i Y_i, \\
N = n + n_s, \\
w_i = \frac{1 - \pi_{s,i}}{\pi_{s,i} \pi_{a,i}} I(S_i = 1) I(A_i = a).
\]</span> <span class="math inline">\(n\)</span> in the estimates can be replaced by the sum of weights to address potential unbounded outcome estimates <a href="">Dahabreh et al.&nbsp;(2019b)</a> <a href="">Dahabreh et al.&nbsp;(2020)</a>. The resulting estimator is more stable, is bounded by the range of observed outcomes, and performs better when the target sample is much larger than the study.</p>
<p>Under regularity conditions, estimates derived using IPPW are consistent and asymptotically normal. Variance can be obtained through either a bootstrap approach (recommended) or robust sandwich estimators.</p>
<p><strong>Additional comments on poststratification:</strong></p>
<p>Propensity scores can be used in the context of poststratification by weighting or matching individuals within strata. RCT individuals are divided into <strong>strata</strong> defined by their propensity scores. Effects are estimated using sample data within each subgroup (such as through separate regressions or a joint regression adding interaction terms), and then the results can be <strong>reweighted</strong> based on the number of target sample individuals in each subgroup. Alternatively, the target sample can be matched to RCT individuals within the same propensity score stratum.</p>
<p>For each strata, the poststratification estimator is asymptotically normal and closed-form variance estimates exist for independent strata. Compared to IPPW, strata reweighting is more likely to be numerically stable and easily implementable when treatment assignment is done at the group level. However, stratification implicitely assumes that treatment effects are identical for study and target patients in the same stratum, which is rarely met and would result in inconsistent estimates and residual confounding. Besides, it also relies on the assumptions that treatment effect heterogeneity is fully captured by the propensity score for treatment and that outcomes are continuous and bounded. Too few or too many strata would both lead to unsatisfying estimates.</p>
</section>
</section>
<section id="outcome-regression-methods" class="level3">
<h3 class="anchored" data-anchor-id="outcome-regression-methods">5.2 Outcome Regression Methods</h3>
<p>Outcome regressions require that the treatment effect is allowed to vary across all effect modifiers in addition to all confounders being correctly included in the regression.</p>
<p>These methods have not been extensively developed for generalizability and transportability.</p>
<section id="outcome-data-from-one-study" class="level4">
<h4 class="anchored" data-anchor-id="outcome-data-from-one-study">5.2.1 Outcome data from one study</h4>
<p>Outcome regression approaches fit an outcome regression in study sample data to estimate conditional means, then obtain PATEs by marginalizing over (i.e.&nbsp;standardizing to) the target sample covariate distribution via predicting counterfactuals for the target sample: <span class="math display">\[
\hat{\mathbb{E}}(Y^{(a)}) = \frac{1}{n} \sum_{i=1}^n \hat{\mathbb{E}}(Y_i|S_i = 1, A_i = a, X_i).
\]</span> If the target sample is not a simple random sample from the target population, this would be a weighted average using sampling weights <a href="">Kim et al.&nbsp;(2018)</a>.</p>
<p>These approaches are particularly effective: - when effect modifiers strongly predict the outcome;</p>
<ul>
<li><p>when when the outcome is common but selection into the study is rare;</p></li>
<li><p>also convenient for exploring PCATEs;</p></li>
<li><p>yield better precision than weighting- or matching-based methods because they can adjust for confounders, effect modifiers, and factors only predictive of the outcome.</p></li>
</ul>
<p>The same regression that was used to estimate impacts within the study can then be used to predict counterfactuals in the target sample.</p>
<p>In the presence of significant lack of overlap between the target and study samples, outcome regressions rely on heavy extrapolation.</p>
<p>An outcome regression is fit with interaction terms between treatment and all effect modifiers before predicting counterfactual outcomes for the target sample.</p>
<p>For RCTs, separate regressions are recommended for each treatment group to better capture treatment effect heterogeneity <a href="">Dahabreh et al.&nbsp;(2019b)</a>. This approach does not borrow information across treatment groups, which is a drawback compared to machine learning methods that discover treatment effect heterogeneity.</p>
<p>BART is the most commonly used (machine learning) data-adaptive outcome regression approach for generalizability and transportability. It models the outcome as a sum of trees with linear additive terms and a regularization prior. It addresses external validity bias via its data-driven discovery of treatment effect heterogeneity. It can also provide confidence intervals from the posterior distribution. However, BART credible intervals show undercoverage when the target population differs substantially fromt he RCT <a href="">Hill (2011)</a>.</p>
</section>
<section id="outcome-data-from-multiple-studies" class="level4">
<h4 class="anchored" data-anchor-id="outcome-data-from-multiple-studies">5.2.2 Outcome data from multiple studies</h4>
<ul>
<li>Bias-adjusted meta-analysis methods: meta-analytic techniques using summary-level study data with no target sample covariate information.
<ul>
<li>Does not explicitely define a target population for whom inference is desired;</li>
<li>Relies on subjective investigator judtements of each study’s level of bias.</li>
</ul></li>
</ul>
<p>…</p>
<ul>
<li>When individual-level outcome data are available in the target sample or from multiple studies, data can be combined into one joint data set for outcome regression analysis. <a href="">Kern et al.&nbsp;(2016)</a>
<ul>
<li>Preferential to IPPW (that usesonly study and not target sample outcome data);</li>
<li>(Drawback:) Will be dominated by observational data results and their potential biases when observational subjects constitute the majority of the joint data set.</li>
</ul></li>
<li>Hierarchical Bayesian evidence synthesis <a href="">Verde et al.&nbsp;(2016)</a> is the regression approach that attempts to empirically adjusted for unobserved confounding when estimating effects for observational patients who are not well-represented in the RCTs.
<ul>
<li>Summary-level RCT data are combined with individual-level observational data through a weighting approach:</li>
<li>Assume that the control group event rate is similar across all studies;</li>
<li>A study quality bias term is added to the observational studies’ outcome regression to account for unmeasured confounding or other uncontrolled biases and to inflate variance.</li>
</ul></li>
</ul>
</section>
</section>
<section id="combined-propensity-score-and-outcome-regression-methods" class="level3">
<h3 class="anchored" data-anchor-id="combined-propensity-score-and-outcome-regression-methods">5.3 Combined Propensity Score and Outcome Regression Methods</h3>
<p><strong>Doubly robust</strong> methods combined outcome and propensity of selection regressions.</p>
<ul>
<li>Asymptotically unbiased when at least one of these regression function is consistently estimated,</li>
<li>Asymptotically efficient when both functions are consistently estimated.</li>
</ul>
<section id="outcome-data-from-one-study-1" class="level4">
<h4 class="anchored" data-anchor-id="outcome-data-from-one-study-1">5.3.1 Outcome data from one study</h4>
<p>Three asymptotically locally efficient doubly robust approaches for <em>randomized data</em>.</p>
<p><strong>Targeted Maximum Likelihood Estimator (TMLE):</strong> <a href="">Rudolph &amp; van Der Laan (2017)</a>.</p>
<ul>
<li><p>A semiparametric substitution estimator that utilizes <em>instrumental variables</em>.</p></li>
<li><p>Developed for transportability in an encouragement design setting and was used for generalizability <a href="">Schmid et al.&nbsp;(2020)</a>;</p></li>
<li><p>PATE estimators for <em>intent to treat</em>, <em>complier</em>, and <em>as treated</em> are developed.</p>
<ul>
<li><p>For all estimators, firstly, use an outcome regression to obtain an initial estimate;</p></li>
<li><p>then adjust that estimate with a fluctuation function using a covariate <span class="math inline">\(C\)</span>;</p></li>
<li><p><span class="math inline">\(C\)</span> is derived from the efficient influence curve and incorporates the propensity of selection information in a bias-reduction step.</p></li>
<li><p>E.g. for the intent to treat PATE, the fluctuation function takes the form <span class="math display">\[
  \operatorname{logit}(\hat{\mathbb{E}}(Y|S=1, A, Z, \mathbf{X}) + \epsilon C),
  \]</span> where <span class="math display">\[
  C = \frac{I(S=1, A=a)}{P(A=a|S=1, \mathbf{X})P(S=1)} \frac{P(Z=z|S=0,A=a,\mathbf{X})P(\mathbf{X}|S=0)}{P(Z=z|S=1,A=a,\mathbf{X})P(\mathbf{X}|S=1)},  
  \]</span> and <span class="math inline">\(Z\)</span> is the intervention taken, and <span class="math inline">\(A\)</span> is the assigned intervention.</p></li>
</ul></li>
</ul>
<p><strong>Augmented Inverse Probability of Participation Weighting (A-IPPW):</strong><br>
<a href="">Dahabreh et al.&nbsp;(2019b)</a> <a href="">(2020)</a></p>
<ul>
<li><p>Equation-based.</p></li>
<li><p>Developed for generalizing results to estimate PATEs for all trial-eligible individuals and transporting results to estimate PATEs for trial-eligible individuals not included in a trial.</p></li>
<li><p>Three estimating equation-based estimators:</p>
<ul>
<li><p>A-IPPW;</p></li>
<li><p>A-IPPW with normalized weights to ensure bounded estimates;</p></li>
<li><p>a weighted outcome regression estimator using participation weights.</p></li>
</ul></li>
<li><p>The nonnormalized A-IPPW estimators for generalizability is <span class="math display">\[
\frac{1}{n} \sum_{i=1}^n \left\{w_i \{Y_i - \hat{\mathbb{E}}(Y_i|S_i=1,A_i=a, X_i)\} +\hat{\mathbb{E}}(Y_i|S_i=1, A_i=a, X_i)\right\},
\]</span> and, for transportability, <span class="math display">\[
\frac{1}{n} \sum_{i=1}^n \left\{w_i \{Y_i - \hat{\mathbb{E}}(Y_i|S_i=1,A_i=a, X_i)\} +\{1-I(S_i = 1)\}\hat{\mathbb{E}}(Y_i|S_i=1, A_i=a, X_i)\right\},
\]</span> where weights <span class="math inline">\(w_i\)</span> are defined as before.</p></li>
</ul>
<p><strong>Augmented Calibration Weighting Estimator:</strong> <a href="">Dong et al.&nbsp;(2020)</a></p>
<ul>
<li>Incorporate outcome information from the target sample when it is available.</li>
<li>Designed for transportability.</li>
<li>Resemble the IPPW estimator, with sampling weights derived through alternative approaches that do not rely on propensity scores.</li>
</ul>
<p><strong>An Alternative Method That Does Not Claim Doubly Robustness:</strong> <a href="">Johansson et al.&nbsp;(2018)</a></p>
<ul>
<li><p>Representational learning approach;</p></li>
<li><p>Regularized neural network estimator for PCATE parameters;</p></li>
<li><p>Jointly learns representations from the data and reweighting function.</p></li>
<li><p>Balance between the study and target covariate distributions and between treated and control distributions in a representational space so that predictors use information common across these distributions and focus on covariates predictive of the outcome.</p></li>
<li><p>Results are reweighted to minimize an upper bound on the expected value of the loss function under the target covariate distribution.</p></li>
</ul>
</section>
<section id="outcome-data-from-multiple-studies-1" class="level4">
<h4 class="anchored" data-anchor-id="outcome-data-from-multiple-studies-1">5.3.2 Outcome data from multiple studies</h4>
<p>Several methods have combined randomized and observational data sources such that they retain internal (randomized) and external (observational) validity.</p>
<ul>
<li>Assumption: the relationship between unmeasured confounders and potential outcomes is the same in the RCT as in the target sample.
<ul>
<li>a weaker assumption than “no unmeasured confounding”.</li>
</ul></li>
</ul>
<p><strong>Cross-design synthesis meta-analysis</strong>:<br>
<a href="">Begg (1992)</a> <a href="">Greenhouse et al.&nbsp;(2017)</a></p>
<ul>
<li><p>When differences in effect modifiers between the RCT and target population are known.</p></li>
<li><p>Estimate treatment effects for patients excluded from the RCT;</p></li>
<li><p>Use summary-level RCT data if outcomes are available by relevant patient subgroups.</p></li>
<li><p>(Drawback:) only accommodate a limited number of strata of relevant effect modifiers.</p></li>
</ul>
<p><strong>Bayesian calibrated risk-adjusted regressions</strong>:<br>
<a href="">Varadhan et al.&nbsp;(2016)</a></p>
<ul>
<li><p>When differences between RCT and target populations are less well understood, there are continuous effect modifiers, or a higher-dimensional set of effect modifiers exists.</p></li>
<li><p>Requires individual-level information from observational randomized studies.</p></li>
<li><p>Relies on (assumptions:) the observational data set having substantial effect modifier overlap with both the target sample and the RCT.</p></li>
</ul>
<p><strong>Two-step (Frequentist) approach for consistently estimating PCATE parameters</strong>: <a href="">Kallus et al.&nbsp;(2018)</a></p>
<ul>
<li><p>Assumption: (calibrating internal validity bias in the subset of the observational data distribution overlapping with RCT data) appropriately calibrates the bias for the entire target sample.</p></li>
<li><p>Outcome regressions for each treatment group of the observational data, or a flexible regression that captures effect heterogeneity.</p></li>
<li><p>Then, observational data are standardized to the RCT population before debiasing their estimates using RCT data (by including a correction term that can depend on measured covariates).</p></li>
<li><p>Does not necessarily decrease bias if the covariate distribution is highly imbalanced.</p></li>
<li><p><a href="">Degtiar et al.&nbsp;(2012)</a> overcome this limitation by standardizing to the observational data itself when debiase observational data estimates. …</p>
<ul>
<li>This approach accommodates outcome regression, propensity weighting, and doubly robust estimators.</li>
</ul></li>
</ul>
<p>…</p>
</section>
</section>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">6. Discussion</h2>
<p>Here are some suggestions when trying to estimate results for populations that go beyond the study population:</p>
<ul>
<li><p>Make efforts to explicitly define target population(s) and identify the study population from which the study sample is a random sample.</p></li>
<li><p>Plan for generalization in the study design, when feasible including writing generalizability considerations into grant or study objectives.(?)!</p></li>
<li><p>Clearly describe the internal and external validity assumptions needed to identify the treatment effect as they relate to the study.</p></li>
<li><p>Quantify the dissimilarity between the study and target populations using at least one method.</p></li>
<li><p>To obtain causal estimates when the target and study populations differ with respect to effect modifiers, incorporate at least one generalizability or transportability estimator. Alternatively, at the minimum, assess and describe sources of effect heterogeneity and whether they are likely to differ for the target population.</p></li>
</ul>
<p>Both internal and external validity are necessary for valid inference!! (Currently much of the causal inference literature focuses on issues of internal validity.)</p>
<p>When treatment effect heterogeneity exists (externally invalid…), as is often the case, study results may not hold for a target population of interest.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>